{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5s Transfer Learning on ESP32 Dataset (2s -> 5s random placement)\n",
    "\n",
    "This notebook keeps the pipeline simple:\n",
    "1. Load your trained 5s base model.\n",
    "2. Load ESP32 2s clips (`cough` and `non_cough`).\n",
    "3. Create synthetic 5s training samples by:\n",
    "   - building a noisy 5s background,\n",
    "   - placing 2s cough randomly inside the 5s window (for cough class).\n",
    "4. Extract MFCC with the same settings as the base model.\n",
    "5. Transfer learn and export model.\n",
    "\n",
    "No zero-padding-only approach is used for cough clips.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a21e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "print('TensorFlow:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b373224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model path: cough_cnn_5s_base.h5\n",
      "ESP32 root: esp32_dataset\n",
      "Public dataset: ..\\public_dataset\n",
      "Target shape (frames, mfcc): (155, 40)\n",
      "USE_PUBLIC_NOISE_IN_TRANSFER: False\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Configuration\n",
    "# =====================\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "BASE_MODEL_CANDIDATES = [\n",
    "    Path('./cough_cnn_5s_base.h5'),\n",
    "    Path('model/cough_cnn_5s_base.h5'),\n",
    "]\n",
    "ESP32_ROOT_CANDIDATES = [\n",
    "    Path('./esp32_dataset'),\n",
    "    Path('model/esp32_dataset'),\n",
    "]\n",
    "PUBLIC_DATASET_CANDIDATES = [\n",
    "    Path('../public_dataset'),\n",
    "    Path('public_dataset'),\n",
    "]\n",
    "\n",
    "\n",
    "def first_existing(paths):\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return paths[0]\n",
    "\n",
    "\n",
    "BASE_MODEL_PATH = first_existing(BASE_MODEL_CANDIDATES)\n",
    "ESP32_ROOT = first_existing(ESP32_ROOT_CANDIDATES)\n",
    "PUBLIC_DATASET_DIR = first_existing(PUBLIC_DATASET_CANDIDATES)\n",
    "\n",
    "COUGH_DIR = ESP32_ROOT / 'cough'\n",
    "NON_COUGH_DIR = ESP32_ROOT / 'non_cough'\n",
    "\n",
    "OUTPUT_PREFIX = 'cough_cnn_5s_transfer_esp32'\n",
    "\n",
    "# Audio setup\n",
    "SR = 16000\n",
    "SRC_SECONDS = 2.0\n",
    "TARGET_SECONDS = 5.0\n",
    "SRC_SAMPLES = int(SR * SRC_SECONDS)\n",
    "TARGET_SAMPLES = int(SR * TARGET_SECONDS)\n",
    "\n",
    "# MFCC (must match base model preprocessing)\n",
    "N_MFCC = 40\n",
    "N_MELS = 128\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "EXPECTED_FRAMES = 1 + int(np.floor((TARGET_SAMPLES - N_FFT) / float(HOP_LENGTH)))\n",
    "\n",
    "# Training setup\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE_FROM_TRAIN = 0.1765  # ~15% val of total\n",
    "BATCH_SIZE = 32\n",
    "HEAD_EPOCHS = 8\n",
    "FINE_TUNE_EPOCHS = 12\n",
    "HEAD_LR = 5e-4\n",
    "FINE_TUNE_LR = 1e-4\n",
    "\n",
    "# Data synthesis controls\n",
    "TRAIN_VERSIONS_PER_SAMPLE = 1  # avoid over-augmenting positives with noise\n",
    "VAL_VERSIONS_PER_SAMPLE = 1\n",
    "TEST_VERSIONS_PER_SAMPLE = 1\n",
    "USE_PUBLIC_NOISE_IN_TRANSFER = False  # keep transfer domain close to ESP32 by default\n",
    "COUGH_SNR_DB_RANGE = (8.0, 20.0)      # keep cough clearly audible in positive samples\n",
    "NON_COUGH_EVENT_SNR_DB_RANGE = (0.0, 18.0)\n",
    "\n",
    "print('Base model path:', BASE_MODEL_PATH)\n",
    "print('ESP32 root:', ESP32_ROOT)\n",
    "print('Public dataset:', PUBLIC_DATASET_DIR)\n",
    "print('Target shape (frames, mfcc):', (EXPECTED_FRAMES, N_MFCC))\n",
    "print('USE_PUBLIC_NOISE_IN_TRANSFER:', USE_PUBLIC_NOISE_IN_TRANSFER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40e48f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESP32 files total: 512\n",
      "Class counts: {0: 258, 1: 254}\n",
      "                                            wav_path  label\n",
      "0  E:\\minor-project\\model\\esp32_dataset\\cough\\cou...      1\n",
      "1  E:\\minor-project\\model\\esp32_dataset\\cough\\cou...      1\n",
      "2  E:\\minor-project\\model\\esp32_dataset\\cough\\cou...      1\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Step 1: Build ESP32 metadata\n",
    "# =====================\n",
    "\n",
    "def collect_labeled_files(folder, label):\n",
    "    if not folder.exists():\n",
    "        return []\n",
    "    rows = []\n",
    "    for wav in sorted(folder.glob('*.wav')):\n",
    "        rows.append({'wav_path': str(wav.resolve()), 'label': int(label)})\n",
    "    return rows\n",
    "\n",
    "rows = []\n",
    "rows += collect_labeled_files(COUGH_DIR, 1)\n",
    "rows += collect_labeled_files(NON_COUGH_DIR, 0)\n",
    "\n",
    "esp32_df = pd.DataFrame(rows)\n",
    "\n",
    "if len(esp32_df) == 0:\n",
    "    raise RuntimeError('No ESP32 wav files found. Check esp32_dataset/cough and esp32_dataset/non_cough')\n",
    "\n",
    "print('ESP32 files total:', len(esp32_df))\n",
    "print('Class counts:', esp32_df['label'].value_counts().to_dict())\n",
    "print(esp32_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4160c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (358, 2) {0: 180, 1: 178}\n",
      "Val:   (77, 2) {0: 39, 1: 38}\n",
      "Test:  (77, 2) {0: 39, 1: 38}\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Step 2: Train/Val/Test split\n",
    "# =====================\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    esp32_df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=esp32_df['label']\n",
    ")\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=VAL_SIZE_FROM_TRAIN,\n",
    "    random_state=SEED,\n",
    "    stratify=train_df['label']\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print('Train:', train_df.shape, train_df['label'].value_counts().to_dict())\n",
    "print('Val:  ', val_df.shape, val_df['label'].value_counts().to_dict())\n",
    "print('Test: ', test_df.shape, test_df['label'].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6dc476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESP32 background pool: 180\n",
      "Public background pool: 0\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Step 3: Noise pools\n",
    "# =====================\n",
    "\n",
    "# Main background pool from ESP32 non-cough clips.\n",
    "ESP32_NOISE_PATHS = train_df.loc[train_df['label'] == 0, 'wav_path'].tolist()\n",
    "\n",
    "# Optional extra noise pool from public dataset non-cough samples (cough_detected <= 0.2).\n",
    "PUBLIC_NOISE_PATHS = []\n",
    "if USE_PUBLIC_NOISE_IN_TRANSFER and PUBLIC_DATASET_DIR.exists():\n",
    "    for wav in sorted(PUBLIC_DATASET_DIR.glob('*.wav')):\n",
    "        js = wav.with_suffix('.json')\n",
    "        if not js.exists():\n",
    "            continue\n",
    "        try:\n",
    "            score = float(json.loads(js.read_text(encoding='utf-8')).get('cough_detected'))\n",
    "            if score <= 0.20:\n",
    "                PUBLIC_NOISE_PATHS.append(str(wav.resolve()))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "print('ESP32 background pool:', len(ESP32_NOISE_PATHS))\n",
    "print('Public background pool:', len(PUBLIC_NOISE_PATHS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99bd42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Step 4: Waveform helpers\n",
    "# =====================\n",
    "\n",
    "\n",
    "def pad_or_trim(y, target_len):\n",
    "    if len(y) < target_len:\n",
    "        y = np.pad(y, (0, target_len - len(y)))\n",
    "    elif len(y) > target_len:\n",
    "        y = y[:target_len]\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "\n",
    "def load_2s_clip(path):\n",
    "    y, _ = librosa.load(path, sr=SR, mono=True, offset=0.0, duration=SRC_SECONDS)\n",
    "    y = pad_or_trim(y, SRC_SAMPLES)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "\n",
    "def load_any_clip(path):\n",
    "    y, _ = librosa.load(path, sr=SR, mono=True)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "\n",
    "def rms(x):\n",
    "    return float(np.sqrt(np.mean(np.square(x), dtype=np.float64) + 1e-10))\n",
    "\n",
    "\n",
    "def mix_at_snr(signal, noise, snr_db):\n",
    "    s = max(rms(signal), 1e-4)\n",
    "    n = max(rms(noise), 1e-6)\n",
    "    target_n = s / (10.0 ** (snr_db / 20.0))\n",
    "    return signal + noise * (target_n / n)\n",
    "\n",
    "\n",
    "def sample_noise_5s(rng):\n",
    "    pool = []\n",
    "    if len(ESP32_NOISE_PATHS) > 0:\n",
    "        pool.extend(ESP32_NOISE_PATHS)\n",
    "    if len(PUBLIC_NOISE_PATHS) > 0:\n",
    "        pool.extend(PUBLIC_NOISE_PATHS)\n",
    "\n",
    "    if len(pool) == 0:\n",
    "        return np.zeros(TARGET_SAMPLES, dtype=np.float32)\n",
    "\n",
    "    p = pool[int(rng.integers(0, len(pool)))]\n",
    "    y = load_any_clip(p)\n",
    "\n",
    "    if len(y) >= TARGET_SAMPLES:\n",
    "        start = int(rng.integers(0, len(y) - TARGET_SAMPLES + 1))\n",
    "        return y[start:start + TARGET_SAMPLES].astype(np.float32)\n",
    "\n",
    "    reps = int(np.ceil(TARGET_SAMPLES / len(y)))\n",
    "    return np.tile(y, reps)[:TARGET_SAMPLES].astype(np.float32)\n",
    "\n",
    "\n",
    "def wind_noise(n, rng):\n",
    "    brown = np.cumsum(rng.normal(0.0, 1.0, n)).astype(np.float32)\n",
    "    brown = brown / (np.max(np.abs(brown)) + 1e-8)\n",
    "    k = max(16, int(0.03 * SR))\n",
    "    kernel = np.ones(k, dtype=np.float32) / k\n",
    "    w = np.convolve(brown, kernel, mode='same')\n",
    "    w = w / (np.max(np.abs(w)) + 1e-8)\n",
    "    return w.astype(np.float32)\n",
    "\n",
    "\n",
    "def pink_noise(n, rng):\n",
    "    white = rng.normal(0.0, 1.0, n)\n",
    "    spec = np.fft.rfft(white)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0 / SR)\n",
    "    scale = np.zeros_like(freqs)\n",
    "    nz = freqs > 0\n",
    "    scale[nz] = 1.0 / np.sqrt(freqs[nz])\n",
    "    pn = np.fft.irfft(spec * scale, n=n)\n",
    "    pn = pn / (np.max(np.abs(pn)) + 1e-8)\n",
    "    return pn.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04d1b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Step 5: Build synthetic 5s sample from 2s clip\n",
    "# =====================\n",
    "\n",
    "def synthesize_5s_from_2s(src_2s, label, rng):\n",
    "    \"\"\"\n",
    "    label=1 (cough): place cough at random position over noisy 5s background.\n",
    "    label=0 (non-cough): place non-cough event + disturbances, so loud noise is learned as non-cough.\n",
    "    \"\"\"\n",
    "    # Start from real background noise\n",
    "    y5 = sample_noise_5s(rng)\n",
    "\n",
    "    # Baseline ambient variation\n",
    "    y5 *= rng.uniform(0.70, 1.20)\n",
    "\n",
    "    if int(label) == 1:\n",
    "        # Keep positive background relatively clean; cough should stay dominant.\n",
    "        if rng.random() < 0.25:\n",
    "            y5 += rng.uniform(0.0005, 0.006) * rng.normal(0.0, 1.0, len(y5)).astype(np.float32)\n",
    "\n",
    "        start = int(rng.integers(0, TARGET_SAMPLES - SRC_SAMPLES + 1))\n",
    "        cough = src_2s.copy() * rng.uniform(0.9, 1.3)\n",
    "\n",
    "        local_bg = y5[start:start + SRC_SAMPLES]\n",
    "        c_rms = max(rms(cough), 1e-6)\n",
    "        b_rms = max(rms(local_bg), 1e-6)\n",
    "        snr_db = float(rng.uniform(COUGH_SNR_DB_RANGE[0], COUGH_SNR_DB_RANGE[1]))\n",
    "        target_cough_rms = b_rms * (10.0 ** (snr_db / 20.0))\n",
    "        cough = cough * (target_cough_rms / c_rms)\n",
    "\n",
    "        y5[start:start + SRC_SAMPLES] += cough\n",
    "\n",
    "    else:\n",
    "        # Non-cough hard negatives: include loud non-cough events to break loudness shortcut.\n",
    "        start = int(rng.integers(0, TARGET_SAMPLES - SRC_SAMPLES + 1))\n",
    "        non_cough_event = src_2s.copy() * rng.uniform(0.8, 1.6)\n",
    "\n",
    "        local_bg = y5[start:start + SRC_SAMPLES]\n",
    "        e_rms = max(rms(non_cough_event), 1e-6)\n",
    "        b_rms = max(rms(local_bg), 1e-6)\n",
    "        snr_db = float(rng.uniform(NON_COUGH_EVENT_SNR_DB_RANGE[0], NON_COUGH_EVENT_SNR_DB_RANGE[1]))\n",
    "        target_event_rms = b_rms * (10.0 ** (snr_db / 20.0))\n",
    "        non_cough_event = non_cough_event * (target_event_rms / e_rms)\n",
    "\n",
    "        y5[start:start + SRC_SAMPLES] += non_cough_event\n",
    "\n",
    "        # Extra disturbances only for non-cough class\n",
    "        if rng.random() < 0.60:\n",
    "            y5 += rng.uniform(0.001, 0.020) * wind_noise(len(y5), rng)\n",
    "        if rng.random() < 0.55:\n",
    "            y5 += rng.uniform(0.001, 0.015) * pink_noise(len(y5), rng)\n",
    "        if rng.random() < 0.50:\n",
    "            y5 += rng.uniform(0.0005, 0.012) * rng.normal(0.0, 1.0, len(y5)).astype(np.float32)\n",
    "        if rng.random() < 0.40:\n",
    "            burst_len = int(rng.integers(int(0.005 * SR), int(0.03 * SR)))\n",
    "            bstart = int(rng.integers(0, max(1, len(y5) - burst_len)))\n",
    "            y5[bstart:bstart + burst_len] += rng.uniform(-0.35, 0.35)\n",
    "\n",
    "    # Gentle compression effect (both classes)\n",
    "    if rng.random() < 0.20:\n",
    "        c = rng.uniform(0.30, 0.90)\n",
    "        y5 = np.tanh(y5 / c) * c\n",
    "\n",
    "    return np.clip(y5, -1.0, 1.0).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef84719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Step 6: MFCC extraction (same settings as base)\n",
    "# =====================\n",
    "\n",
    "def extract_mfcc_2d(y,\n",
    "                    sr=SR,\n",
    "                    n_mfcc=N_MFCC,\n",
    "                    n_mels=N_MELS,\n",
    "                    n_fft=N_FFT,\n",
    "                    hop_length=HOP_LENGTH,\n",
    "                    max_frames=EXPECTED_FRAMES,\n",
    "                    normalise=True):\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_mfcc=n_mfcc,\n",
    "        n_mels=n_mels,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        htk=False,\n",
    "    )\n",
    "\n",
    "    mfcc = mfcc.T.astype(np.float32)\n",
    "\n",
    "    if mfcc.shape[0] < max_frames:\n",
    "        pad = np.zeros((max_frames - mfcc.shape[0], n_mfcc), dtype=np.float32)\n",
    "        mfcc = np.vstack([mfcc, pad])\n",
    "    elif mfcc.shape[0] > max_frames:\n",
    "        mfcc = mfcc[:max_frames, :]\n",
    "\n",
    "    if normalise:\n",
    "        mean = np.mean(mfcc, axis=0, keepdims=True)\n",
    "        std = np.std(mfcc, axis=0, keepdims=True) + 1e-6\n",
    "        mfcc = (mfcc - mean) / std\n",
    "\n",
    "    return mfcc.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a0a8669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [00:05<00:00, 61.81it/s] \n",
      "100%|██████████| 77/77 [00:00<00:00, 88.31it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 82.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (358, 155, 40) y_train: (358,)\n",
      "X_val:   (77, 155, 40) y_val:   (77,)\n",
      "X_test:  (77, 155, 40) y_test:  (77,)\n",
      "Train class counts: {0: 180, 1: 178}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Step 7: Build feature tensors\n",
    "# =====================\n",
    "\n",
    "def build_feature_set(split_df, versions_per_sample=1, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    total = len(split_df) * int(versions_per_sample)\n",
    "    X = np.zeros((total, EXPECTED_FRAMES, N_MFCC), dtype=np.float32)\n",
    "    y = np.zeros((total,), dtype=np.int32)\n",
    "\n",
    "    idx = 0\n",
    "    for row in tqdm(split_df.itertuples(index=False), total=len(split_df)):\n",
    "        src_2s = load_2s_clip(row.wav_path)\n",
    "        label = int(row.label)\n",
    "\n",
    "        for _ in range(int(versions_per_sample)):\n",
    "            y5 = synthesize_5s_from_2s(src_2s, label, rng)\n",
    "            y5 = y5.astype(np.float32)\n",
    "            X[idx] = extract_mfcc_2d(y5)\n",
    "            y[idx] = label\n",
    "            idx += 1\n",
    "\n",
    "    return X[:idx], y[:idx]\n",
    "\n",
    "\n",
    "X_train, y_train = build_feature_set(train_df, versions_per_sample=TRAIN_VERSIONS_PER_SAMPLE, seed=SEED)\n",
    "X_val, y_val = build_feature_set(val_df, versions_per_sample=VAL_VERSIONS_PER_SAMPLE, seed=SEED + 1)\n",
    "X_test, y_test = build_feature_set(test_df, versions_per_sample=TEST_VERSIONS_PER_SAMPLE, seed=SEED + 2)\n",
    "\n",
    "print('X_train:', X_train.shape, 'y_train:', y_train.shape)\n",
    "print('X_val:  ', X_val.shape, 'y_val:  ', y_val.shape)\n",
    "print('X_test: ', X_test.shape, 'y_test: ', y_test.shape)\n",
    "print('Train class counts:', {0:int(np.sum(y_train==0)), 1:int(np.sum(y_train==1))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06be9aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.9944444444444445, 1: 1.0056179775280898}\n"
     ]
    }
   ],
   "source": [
    "# Labels + class weights\n",
    "y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "y_val_onehot = to_categorical(y_val, num_classes=2)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array([0, 1]),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight = {0: float(class_weights[0]), 1: float(class_weights[1])}\n",
    "\n",
    "print('Class weights:', class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86068112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base model from: cough_cnn_5s_base.h5\n",
      "Epoch 1/8\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0903 - accuracy: 0.5251 \n",
      "Epoch 1: val_loss improved from inf to 1.00509, saving model to cough_cnn_5s_transfer_esp32_head.h5\n",
      "12/12 [==============================] - 3s 56ms/step - loss: 1.0903 - accuracy: 0.5251 - val_loss: 1.0051 - val_accuracy: 0.4935 - lr: 5.0000e-04\n",
      "Epoch 2/8\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.8832 - accuracy: 0.5938\n",
      "Epoch 2: val_loss improved from 1.00509 to 0.87555, saving model to cough_cnn_5s_transfer_esp32_head.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.9037 - accuracy: 0.5279 - val_loss: 0.8755 - val_accuracy: 0.4805 - lr: 5.0000e-04\n",
      "Epoch 3/8\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.9720 - accuracy: 0.5000\n",
      "Epoch 3: val_loss improved from 0.87555 to 0.79889, saving model to cough_cnn_5s_transfer_esp32_head.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8073 - accuracy: 0.5531 - val_loss: 0.7989 - val_accuracy: 0.4675 - lr: 5.0000e-04\n",
      "Epoch 4/8\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.7536 - accuracy: 0.5531\n",
      "Epoch 4: val_loss improved from 0.79889 to 0.75927, saving model to cough_cnn_5s_transfer_esp32_head.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7471 - accuracy: 0.5531 - val_loss: 0.7593 - val_accuracy: 0.4805 - lr: 5.0000e-04\n",
      "Epoch 5/8\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7148 - accuracy: 0.5698\n",
      "Epoch 5: val_loss improved from 0.75927 to 0.73632, saving model to cough_cnn_5s_transfer_esp32_head.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7148 - accuracy: 0.5698 - val_loss: 0.7363 - val_accuracy: 0.4935 - lr: 5.0000e-04\n",
      "Epoch 6/8\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.6829 - accuracy: 0.5312\n",
      "Epoch 6: val_loss improved from 0.73632 to 0.72119, saving model to cough_cnn_5s_transfer_esp32_head.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6963 - accuracy: 0.5726 - val_loss: 0.7212 - val_accuracy: 0.4935 - lr: 5.0000e-04\n",
      "Epoch 7/8\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.5866\n",
      "Epoch 7: val_loss improved from 0.72119 to 0.71030, saving model to cough_cnn_5s_transfer_esp32_head.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5866 - val_loss: 0.7103 - val_accuracy: 0.5195 - lr: 5.0000e-04\n",
      "Epoch 8/8\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6766 - accuracy: 0.5950\n",
      "Epoch 8: val_loss improved from 0.71030 to 0.70415, saving model to cough_cnn_5s_transfer_esp32_head.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6766 - accuracy: 0.5950 - val_loss: 0.7041 - val_accuracy: 0.5195 - lr: 5.0000e-04\n",
      "Epoch 1/12\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9195 - accuracy: 0.5447\n",
      "Epoch 1: val_loss improved from inf to 0.68920, saving model to cough_cnn_5s_transfer_esp32.h5\n",
      "12/12 [==============================] - 2s 51ms/step - loss: 0.9195 - accuracy: 0.5447 - val_loss: 0.6892 - val_accuracy: 0.5325 - lr: 1.0000e-04\n",
      "Epoch 2/12\n",
      " 6/12 [==============>...............] - ETA: 0s - loss: 0.8185 - accuracy: 0.5885\n",
      "Epoch 2: val_loss improved from 0.68920 to 0.68221, saving model to cough_cnn_5s_transfer_esp32.h5\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.8356 - accuracy: 0.5587 - val_loss: 0.6822 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 3/12\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.7934 - accuracy: 0.5938\n",
      "Epoch 3: val_loss improved from 0.68221 to 0.68120, saving model to cough_cnn_5s_transfer_esp32.h5\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7825 - accuracy: 0.5978 - val_loss: 0.6812 - val_accuracy: 0.5455 - lr: 1.0000e-04\n",
      "Epoch 4/12\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 0.6837 - accuracy: 0.6071\n",
      "Epoch 4: val_loss did not improve from 0.68120\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7268 - accuracy: 0.5922 - val_loss: 0.6815 - val_accuracy: 0.5455 - lr: 1.0000e-04\n",
      "Epoch 5/12\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6990 - accuracy: 0.6389\n",
      "Epoch 5: val_loss did not improve from 0.68120\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.6313 - val_loss: 0.6821 - val_accuracy: 0.5584 - lr: 1.0000e-04\n",
      "Epoch 6/12\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6886 - accuracy: 0.6181\n",
      "Epoch 6: val_loss did not improve from 0.68120\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6721 - accuracy: 0.6313 - val_loss: 0.6849 - val_accuracy: 0.5584 - lr: 1.0000e-04\n",
      "Epoch 7/12\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 0.6541 - accuracy: 0.6836\n",
      "Epoch 7: val_loss did not improve from 0.68120\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6314 - accuracy: 0.6816 - val_loss: 0.6853 - val_accuracy: 0.5584 - lr: 5.0000e-05\n",
      "Epoch 8/12\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6464 - accuracy: 0.6676\n",
      "Epoch 8: val_loss did not improve from 0.68120\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6410 - accuracy: 0.6732 - val_loss: 0.6849 - val_accuracy: 0.5584 - lr: 5.0000e-05\n",
      "Epoch 9/12\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 0.6090 - accuracy: 0.6719\n",
      "Epoch 9: val_loss did not improve from 0.68120\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6195 - accuracy: 0.6592 - val_loss: 0.6842 - val_accuracy: 0.5455 - lr: 5.0000e-05\n",
      "Epoch 9: early stopping\n",
      "Loaded best transfer model: cough_cnn_5s_transfer_esp32.h5\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Step 8: Transfer learning\n",
    "# =====================\n",
    "if not BASE_MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f'Base model not found: {BASE_MODEL_PATH}')\n",
    "\n",
    "model = keras.models.load_model(str(BASE_MODEL_PATH))\n",
    "print('Loaded base model from:', BASE_MODEL_PATH)\n",
    "\n",
    "# Phase 1: freeze most layers, train only top layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=HEAD_LR),\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.03),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{OUTPUT_PREFIX}_head.h5',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-5,\n",
    "        verbose=1,\n",
    "    ),\n",
    "]\n",
    "\n",
    "history_head = model.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    validation_data=(X_val, y_val_onehot),\n",
    "    epochs=HEAD_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Phase 2: unfreeze all, fine-tune with lower LR\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks_ft = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{OUTPUT_PREFIX}.h5',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        patience=6,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "\n",
    "history_ft = model.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    validation_data=(X_val, y_val_onehot),\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks_ft,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model = keras.models.load_model(f'{OUTPUT_PREFIX}.h5')\n",
    "print('Loaded best transfer model:', f'{OUTPUT_PREFIX}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56967a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "Val probability summary:\n",
      "             count      mean      std       min       25%       50%       75%  \\\n",
      "p_cough       77.0  0.450966  0.14087  0.081205  0.381805  0.443077  0.546257   \n",
      "p_non_cough   77.0  0.549034  0.14087  0.240031  0.453743  0.556923  0.618195   \n",
      "\n",
      "                  max  \n",
      "p_cough      0.759969  \n",
      "p_non_cough  0.918795  \n",
      "\n",
      "Test probability summary:\n",
      "             count      mean       std       min       25%       50%  \\\n",
      "p_cough       77.0  0.451555  0.148593  0.097577  0.361660  0.433655   \n",
      "p_non_cough   77.0  0.548445  0.148593  0.174669  0.440806  0.566345   \n",
      "\n",
      "                  75%       max  \n",
      "p_cough      0.559194  0.825330  \n",
      "p_non_cough  0.638340  0.902423  \n",
      "\n",
      "Raw probability preview (first 20 test samples):\n",
      "    y_true  pred   p_cough  p_non_cough\n",
      "0        1     1  0.599284     0.400716\n",
      "1        1     1  0.511056     0.488944\n",
      "2        0     0  0.489676     0.510324\n",
      "3        0     0  0.102863     0.897137\n",
      "4        1     0  0.285394     0.714606\n",
      "5        0     0  0.379589     0.620411\n",
      "6        0     1  0.825330     0.174669\n",
      "7        0     0  0.452313     0.547687\n",
      "8        0     0  0.407338     0.592662\n",
      "9        0     0  0.478131     0.521869\n",
      "10       0     0  0.474857     0.525143\n",
      "11       0     0  0.361660     0.638340\n",
      "12       1     1  0.670771     0.329229\n",
      "13       1     0  0.419359     0.580641\n",
      "14       0     0  0.497225     0.502775\n",
      "15       1     1  0.612023     0.387977\n",
      "16       1     1  0.554957     0.445043\n",
      "17       1     0  0.444552     0.555448\n",
      "18       0     0  0.097577     0.902423\n",
      "19       0     0  0.327699     0.672301\n",
      "\n",
      "Confusion matrix (test, argmax):\n",
      "[[31  8]\n",
      " [19 19]]\n",
      "\n",
      "Classification report (test, argmax):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6200    0.7949    0.6966        39\n",
      "           1     0.7037    0.5000    0.5846        38\n",
      "\n",
      "    accuracy                         0.6494        77\n",
      "   macro avg     0.6619    0.6474    0.6406        77\n",
      "weighted avg     0.6613    0.6494    0.6413        77\n",
      "\n",
      "Test AUC (using p_cough): 0.6869095816464238\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Step 9: Raw probabilities + test metrics (argmax decision)\n",
    "# =====================\n",
    "val_pred_prob = model.predict(X_val, batch_size=BATCH_SIZE, verbose=1)\n",
    "test_pred_prob = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "# Raw class probabilities\n",
    "val_prob_non_cough = val_pred_prob[:, 0]\n",
    "val_prob_cough = val_pred_prob[:, 1]\n",
    "\n",
    "test_prob_non_cough = test_pred_prob[:, 0]\n",
    "test_prob_cough = test_pred_prob[:, 1]\n",
    "\n",
    "# No threshold tuning: use class argmax directly\n",
    "test_pred = np.argmax(test_pred_prob, axis=1).astype(np.int32)\n",
    "\n",
    "print('Val probability summary:')\n",
    "print(pd.DataFrame({\n",
    "    'p_cough': val_prob_cough,\n",
    "    'p_non_cough': val_prob_non_cough\n",
    "}).describe().T)\n",
    "\n",
    "print('\\nTest probability summary:')\n",
    "print(pd.DataFrame({\n",
    "    'p_cough': test_prob_cough,\n",
    "    'p_non_cough': test_prob_non_cough\n",
    "}).describe().T)\n",
    "\n",
    "preview_df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'pred': test_pred,\n",
    "    'p_cough': test_prob_cough,\n",
    "    'p_non_cough': test_prob_non_cough,\n",
    "})\n",
    "\n",
    "print('\\nRaw probability preview (first 20 test samples):')\n",
    "print(preview_df.head(20))\n",
    "\n",
    "print('\\nConfusion matrix (test, argmax):')\n",
    "print(confusion_matrix(y_test, test_pred))\n",
    "\n",
    "print('\\nClassification report (test, argmax):')\n",
    "print(classification_report(y_test, test_pred, digits=4))\n",
    "\n",
    "print('Test AUC (using p_cough):', roc_auc_score(y_test, test_prob_cough))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2207f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved report: E:\\minor-project\\model\\cough_cnn_5s_transfer_esp32_report.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Aman\\AppData\\Local\\Temp\\tmpsfli8_rb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Aman\\AppData\\Local\\Temp\\tmpsfli8_rb\\assets\n",
      "c:\\Users\\Aman\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tflite: E:\\minor-project\\model\\cough_cnn_5s_transfer_esp32_int8.tflite\n",
      "Input quantization: (0.05734632909297943, -4) dtype: <class 'numpy.int8'> shape: [  1 155  40]\n",
      "Output quantization: (0.00390625, -128) dtype: <class 'numpy.int8'> shape: [1 2]\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Step 10: Save report + TFLite\n",
    "# =====================\n",
    "report = {\n",
    "    'output_prefix': OUTPUT_PREFIX,\n",
    "    'base_model_path': str(BASE_MODEL_PATH),\n",
    "    'seed': SEED,\n",
    "    'audio': {\n",
    "        'sr': SR,\n",
    "        'src_seconds': SRC_SECONDS,\n",
    "        'target_seconds': TARGET_SECONDS,\n",
    "        'src_samples': SRC_SAMPLES,\n",
    "        'target_samples': TARGET_SAMPLES,\n",
    "    },\n",
    "    'mfcc': {\n",
    "        'n_mfcc': N_MFCC,\n",
    "        'n_mels': N_MELS,\n",
    "        'n_fft': N_FFT,\n",
    "        'hop_length': HOP_LENGTH,\n",
    "        'expected_frames': EXPECTED_FRAMES,\n",
    "    },\n",
    "    'counts': {\n",
    "        'esp32_files_total': int(len(esp32_df)),\n",
    "        'train_files': int(len(train_df)),\n",
    "        'val_files': int(len(val_df)),\n",
    "        'test_files': int(len(test_df)),\n",
    "        'train_samples_after_synthesis': int(len(y_train)),\n",
    "        'val_samples_after_synthesis': int(len(y_val)),\n",
    "        'test_samples_after_synthesis': int(len(y_test)),\n",
    "        'esp32_noise_pool': int(len(ESP32_NOISE_PATHS)),\n",
    "        'public_noise_pool': int(len(PUBLIC_NOISE_PATHS)),\n",
    "    },\n",
    "    'synthesis': {\n",
    "        'train_versions_per_sample': TRAIN_VERSIONS_PER_SAMPLE,\n",
    "        'val_versions_per_sample': VAL_VERSIONS_PER_SAMPLE,\n",
    "        'test_versions_per_sample': TEST_VERSIONS_PER_SAMPLE,\n",
    "        'cough_insert_random_position': True,\n",
    "        'zero_padding_only': False,\n",
    "    },\n",
    "    'decision_rule': 'argmax(class_probabilities)',\n",
    "    'test_auc': float(roc_auc_score(y_test, test_prob_cough)),\n",
    "    'classification_report': classification_report(y_test, test_pred, output_dict=True, digits=6),\n",
    "    'confusion_matrix': confusion_matrix(y_test, test_pred).tolist(),\n",
    "    # Keep a tiny preview so report stays small but still shows raw scores.\n",
    "    'test_probability_preview_first_20': [\n",
    "        {\n",
    "            'y_true': int(y_test[i]),\n",
    "            'pred': int(test_pred[i]),\n",
    "            'p_cough': float(test_prob_cough[i]),\n",
    "            'p_non_cough': float(test_prob_non_cough[i]),\n",
    "        }\n",
    "        for i in range(min(20, len(test_pred)))\n",
    "    ],\n",
    "}\n",
    "\n",
    "report_path = Path(f'{OUTPUT_PREFIX}_report.json')\n",
    "report_path.write_text(json.dumps(report, indent=2), encoding='utf-8')\n",
    "print('Saved report:', report_path.resolve())\n",
    "\n",
    "\n",
    "def representative_data_gen():\n",
    "    n = min(300, len(X_train))\n",
    "    idx = np.random.choice(len(X_train), size=n, replace=False)\n",
    "    for i in idx:\n",
    "        yield [X_train[i:i+1].astype(np.float32)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "quant_tflite = converter.convert()\n",
    "tflite_path = Path(f'{OUTPUT_PREFIX}_int8.tflite')\n",
    "tflite_path.write_bytes(quant_tflite)\n",
    "print('Saved tflite:', tflite_path.resolve())\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_path))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "in_d = interpreter.get_input_details()[0]\n",
    "out_d = interpreter.get_output_details()[0]\n",
    "\n",
    "print('Input quantization:', in_d['quantization'], 'dtype:', in_d['dtype'], 'shape:', in_d['shape'])\n",
    "print('Output quantization:', out_d['quantization'], 'dtype:', out_d['dtype'], 'shape:', out_d['shape'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f96af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434db66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}